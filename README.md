# SIADS-699_PEFT-Testers

## Overview
LLMs are powerful general-purpose tools, but they often hallucinate and can be unreliable in specialized fields like medicine or law. Full fine-tuning helps to alleviate this issue, but the process is computationally expensive and time consuming. Parameter-Efficient Fine-Tuning (PEFT) methods offer a solution. These techniques involve training only a small subset of the model's parameters to align it with specialized knowledge without the prohibitive computational cost. This project was designed to evaluate three popular PEFT methods: Low-Rank Adaptation (LoRA), Weight Decomposed Low-Rank Adaptation (DoRA), and Prefix Tuning, to assess their comparative performance, computational cost, and optimal use cases.

## Repository Structure
ðŸ“¦ lighteval
â”œâ”€â”€ ðŸ“‚ notebooks
â”‚   â”œâ”€â”€ ðŸ“„ eda.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_3-8b_prefix_tune.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_config_subsets.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_dora.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_dora_letters.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_lora.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_lora_letters.ipynb
â”‚   â”œâ”€â”€ ðŸ“„ peft_prefix_tune.ipynb
â”‚   â””â”€â”€ ðŸ“„ preprocess-usmle.ipynb
â”œâ”€â”€ ðŸ“‚ src
â”‚   â”œâ”€â”€ ðŸ“‚ eval
â”‚   â”‚   â””â”€â”€ ðŸ“„ evaluation.py
â”‚   â””â”€â”€ ðŸ“„ helper_functions.py
â”œâ”€â”€ ðŸ“„ .gitignore
â”œâ”€â”€ ðŸ“„ LICENSE
â”œâ”€â”€ ðŸ“„ README.md
â””â”€â”€ ðŸ“„ requirements.txt
